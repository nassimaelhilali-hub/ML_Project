{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bfebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737876e",
   "metadata": {},
   "source": [
    "Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da66636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'ragno', 'sheep', 'squirrel']\n",
      "Index des classes: {'butterfly': 0, 'cat': 1, 'chicken': 2, 'cow': 3, 'dog': 4, 'elephant': 5, 'horse': 6, 'ragno': 7, 'sheep': 8, 'squirrel': 9}\n"
     ]
    }
   ],
   "source": [
    "# Transformations pour normaliser les images et les redimensionner\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Redimensionner les images\n",
    "    transforms.ToTensor(),          # Convertir en tenseur PyTorch\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],  # Normalisation\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Charger les données avec ImageFolder\n",
    "dataset = datasets.ImageFolder(root=\"data_img\", transform=transform)\n",
    "\n",
    "# Créer un DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Obtenir la correspondance des classes\n",
    "print(\"Classes:\", dataset.classes)\n",
    "print(\"Index des classes:\", dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e407add",
   "metadata": {},
   "source": [
    "Sélectionner un échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c3c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'ragno', 'sheep', 'squirrel']\n",
      "Index des classes: {'butterfly': 0, 'cat': 1, 'chicken': 2, 'cow': 3, 'dog': 4, 'elephant': 5, 'horse': 6, 'ragno': 7, 'sheep': 8, 'squirrel': 9}\n",
      "Nombre d'images par classe :\n",
      "Classe sheep : 10 images\n",
      "Classe cat : 10 images\n",
      "Classe squirrel : 10 images\n",
      "Classe dog : 10 images\n",
      "Classe butterfly : 10 images\n",
      "Classe elephant : 10 images\n",
      "Classe ragno : 10 images\n",
      "Classe cow : 10 images\n",
      "Classe horse : 10 images\n",
      "Classe chicken : 10 images\n"
     ]
    }
   ],
   "source": [
    "# Obtenir la correspondance des classes\n",
    "print(\"Classes:\", dataset.classes)\n",
    "print(\"Index des classes:\", dataset.class_to_idx)\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les images et labels\n",
    "class_images = defaultdict(list)\n",
    "class_labels = defaultdict(list)\n",
    "\n",
    "# Limiter à 100 images par classe\n",
    "max_images_per_class = 10\n",
    "\n",
    "# Parcourir les lots d'images\n",
    "for images, labels in data_loader:\n",
    "    for image, label in zip(images, labels):\n",
    "        class_images[label.item()].append(image)\n",
    "        class_labels[label.item()].append(label.item())\n",
    "\n",
    "        # Arrêter dès qu'on a 100 images pour chaque classe\n",
    "        if all(len(class_images[class_idx]) >= max_images_per_class for class_idx in class_images):\n",
    "            break\n",
    "    else:\n",
    "        continue  # Si break n'a pas été appelé, continuer à parcourir le batch\n",
    "    break  # Sortir de la boucle principale quand on a atteint 100 images pour chaque classe\n",
    "\n",
    "# Limiter à 10 images pour chaque classe\n",
    "for class_idx in class_images:\n",
    "    class_images[class_idx] = class_images[class_idx][:max_images_per_class]\n",
    "    class_labels[class_idx] = class_labels[class_idx][:max_images_per_class]\n",
    "\n",
    "# Afficher la forme des images et labels pour vérifier\n",
    "print(f\"Nombre d'images par classe :\")\n",
    "for class_idx, images in class_images.items():\n",
    "    print(f\"Classe {dataset.classes[class_idx]} : {len(images)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3390dda",
   "metadata": {},
   "source": [
    "<h3> Créer un nouveau dataset <h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9119c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128]) tensor([0, 7, 4, 1, 6, 3, 8, 8, 2, 4, 3, 2, 9, 3, 0, 4, 2, 5, 8, 0, 0, 2, 6, 5,\n",
      "        5, 7, 7, 4, 8, 9, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SubsetDataset(Dataset):\n",
    "    def __init__(self, class_images, class_labels):\n",
    "        self.class_images = class_images\n",
    "        self.class_labels = class_labels\n",
    "        # Créer une liste de toutes les images et labels à partir des dictionnaires\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for label, images in class_images.items():\n",
    "            self.images.extend(images)\n",
    "            self.labels.extend([label] * len(images))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Créer un nouveau dataset avec les images collectées\n",
    "subset_dataset = SubsetDataset(class_images, class_labels)\n",
    "\n",
    "# Créer un DataLoader pour ce subset\n",
    "subset_loader = torch.utils.data.DataLoader(subset_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Afficher un exemple de lot d'images et labels\n",
    "for images, labels in subset_loader:\n",
    "    print(images.shape, labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf6e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "train_size = int(0.8 * len(subset_dataset))  # 80% pour l'entraînement\n",
    "valid_size = len(subset_dataset) - train_size  # 20% pour la validation\n",
    "\n",
    "# Diviser le dataset en deux partitions : train et valid\n",
    "train_dataset, valid_dataset = random_split(subset_dataset, [train_size, valid_size])\n",
    "\n",
    "# Créer un DataLoader pour ces data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40e0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad657d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Animals(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# === 2. Définition du modèle CNN ===\n",
    "class CNN_Animals(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # --- Couches convolutionnelles ---\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # --- Couches fully connected ---\n",
    "        # Après 3 convolutions + 3 poolings : 128x128 → 16x16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # aplatir\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# === 3. Initialisation du modèle ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_Animals(num_classes=10).to(device)\n",
    "print(model)\n",
    "\n",
    "# === 4. Définition de la fonction de perte et de l’optimiseur ===\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# === 5. Fonction d'entraînement ===\n",
    "def train_loop(loader, model, loss_fn, optimizer, log=True):\n",
    "    size = len(loader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # forward\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if log and batch % 10 == 0:\n",
    "            current = (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"🔹 Moyenne de la loss sur l'époque : {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c2e7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Époque 1 =====\n",
      "loss: 1.755813  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 1.5694\n",
      "\n",
      "===== Époque 2 =====\n",
      "loss: 1.215848  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 1.2078\n",
      "\n",
      "===== Époque 3 =====\n",
      "loss: 0.887923  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 1.0405\n",
      "\n",
      "===== Époque 4 =====\n",
      "loss: 0.734020  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.9823\n",
      "\n",
      "===== Époque 5 =====\n",
      "loss: 0.600018  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.6574\n",
      "\n",
      "===== Époque 6 =====\n",
      "loss: 0.662158  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.6488\n",
      "\n",
      "===== Époque 7 =====\n",
      "loss: 0.297627  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.4045\n",
      "\n",
      "===== Époque 8 =====\n",
      "loss: 0.408294  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.3614\n",
      "\n",
      "===== Époque 9 =====\n",
      "loss: 0.118275  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.1510\n",
      "\n",
      "===== Époque 10 =====\n",
      "loss: 0.102871  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.1206\n"
     ]
    }
   ],
   "source": [
    "# === 6. Lancer l'entraînement (ex : 3 époques) ===\n",
    "for epoch in range(10):\n",
    "    print(f\"\\n===== Époque {epoch+1} =====\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff12af",
   "metadata": {},
   "source": [
    "<h3> Evaluation du modèle <h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals():\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656d4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(loader, model, loss_fn, log=True):\n",
    "    model.eval() #evaluating the model\n",
    "    size = len(loader.dataset)\n",
    "    num_batches = len(loader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    if log:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf2646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.049954  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.0680\n",
      "Test Error: \n",
      " Accuracy: 25.0%, loss: 4.522668 \n",
      "\n",
      "loss: 0.255205  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.1357\n",
      "Test Error: \n",
      " Accuracy: 15.0%, loss: 5.070909 \n",
      "\n",
      "loss: 0.133264  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.0855\n",
      "Test Error: \n",
      " Accuracy: 10.0%, loss: 5.968122 \n",
      "\n",
      "loss: 0.292206  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.1518\n",
      "Test Error: \n",
      " Accuracy: 35.0%, loss: 4.524742 \n",
      "\n",
      "loss: 0.053805  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.1058\n",
      "Test Error: \n",
      " Accuracy: 30.0%, loss: 4.098357 \n",
      "\n",
      "loss: 0.016111  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.0765\n",
      "Test Error: \n",
      " Accuracy: 20.0%, loss: 4.510278 \n",
      "\n",
      "loss: 0.039718  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.2048\n",
      "Test Error: \n",
      " Accuracy: 15.0%, loss: 4.788084 \n",
      "\n",
      "loss: 0.038378  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.0393\n",
      "Test Error: \n",
      " Accuracy: 15.0%, loss: 4.971359 \n",
      "\n",
      "loss: 0.030310  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.0184\n",
      "Test Error: \n",
      " Accuracy: 15.0%, loss: 5.324303 \n",
      "\n",
      "loss: 0.030986  [   32/   80]\n",
      "🔹 Moyenne de la loss sur l'époque : 0.0396\n",
      "Test Error: \n",
      " Accuracy: 20.0%, loss: 5.145842 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_test = []\n",
    "loss_train = []\n",
    "acc_test = []\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"\\n===== Époque {t+1} =====\")\n",
    "    loss_train.append(train_loop(train_loader, model, loss_fn, optimizer))\n",
    "    l, a = test_loop(valid_loader, model, loss_fn)\n",
    "    loss_test.append(l)\n",
    "    acc_test.append(a)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a882423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
